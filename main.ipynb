{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e5e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import  transforms, datasets\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import random_split, DataLoader, Subset, Dataset\n",
    "from PIL import Image\n",
    "# from torchvision.transforms import InterpolationMode\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "# from transformers import SwinForImageClassification, AutoImageProcessor, AutoModelForZeroShotImageClassification\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import models\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dd2cb7",
   "metadata": {},
   "source": [
    "# Define variable enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d282da",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2504\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d65e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FOLDER_PATH = './data/test'\n",
    "TRAIN_FOLDER_PATH = './data/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82876f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    \"đông cô\": \"1\",\n",
    "    \"tai mèo\": \"2\",\n",
    "    \"tuyết khô\": \"0\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd71cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img_tensor):\n",
    "    img = img_tensor.permute(1, 2, 0) \n",
    "    img = img.numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cbd3a4",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c8816",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((300, 300)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.2),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "    \n",
    "        transforms.ColorJitter(brightness=0.6, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.RandomAdjustSharpness(sharpness_factor=4, p=0.5),\n",
    "        transforms.RandomAutocontrast(p=0.4),\n",
    "        transforms.RandomEqualize(p=0.2),\n",
    "    \n",
    "        transforms.ToTensor(),\n",
    "        transforms.GaussianBlur(kernel_size=(5,9), sigma=(0.1,5)),\n",
    "        transforms.RandomErasing(\n",
    "            p=0.3,\n",
    "            scale=(0.02, 0.10),       \n",
    "            ratio=(0.3, 3.3),         \n",
    "            value='random'            \n",
    "        ),\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "])\n",
    "\n",
    "# train_transform = transforms.Compose([\n",
    "#     # Crop với padding giúp model học được vùng viền\n",
    "#     transforms.RandomCrop(32, padding=4),     \n",
    "#     # Lật ngang (và lật dọc nếu nấm không phân biệt trên/dưới)\n",
    "#     transforms.RandomHorizontalFlip(p=0.5),   \n",
    "#     # Xoay nhẹ ±20 độ\n",
    "#     transforms.RandomRotation(20),            \n",
    "#     # Áp policy của CIFAR10 (AutoAugment)\n",
    "#     transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
    "#     # Điều chỉnh sáng/tương phản nhẹ\n",
    "#     transforms.ColorJitter(\n",
    "#         brightness=0.2, \n",
    "#         contrast=0.2, \n",
    "#         saturation=0.2, \n",
    "#         hue=0.05\n",
    "#     ),\n",
    "#     transforms.ToTensor(),\n",
    "#     # Occlude ngẫu nhiên 1 vùng (cutout-like)\n",
    "#     transforms.RandomErasing(\n",
    "#         p=0.3, \n",
    "#         scale=(0.02, 0.1), \n",
    "#         ratio=(0.3, 3.3), \n",
    "#         value=0\n",
    "#     ),\n",
    "#     transforms.Normalize(mean=mean, std=std),\n",
    "# ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf2c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, test_dir, transform=None):\n",
    "        self.test_dir = test_dir\n",
    "        self.image_paths = sorted([os.path.join(test_dir, fname)\n",
    "                                   for fname in os.listdir(test_dir)\n",
    "                                   if fname.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, os.path.basename(img_path) \n",
    "\n",
    "class SubsetWithTransform(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset, transform):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.subset[idx]       \n",
    "        if self.transform:\n",
    "            image = self.transform(image)     \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45407bb3",
   "metadata": {},
   "source": [
    "# Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b0926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset = datasets.ImageFolder(root=TRAIN_FOLDER_PATH,transform=None)\n",
    "dataset_size = len(base_dataset)\n",
    "\n",
    "# train/val\n",
    "val_size     = int(0.2 * dataset_size)\n",
    "train_size   = dataset_size - val_size\n",
    "train_subset, val_subset = random_split(base_dataset, [train_size, val_size],generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "train_dataset = SubsetWithTransform(train_subset, transform)\n",
    "val_dataset   = SubsetWithTransform(val_subset,   test_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=32, shuffle=False)\n",
    "\n",
    "# test\n",
    "test_dir = TEST_FOLDER_PATH\n",
    "test_dataset = CustomTestDataset(test_dir, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "class_names = base_dataset.classes\n",
    "print(\"Classes:\", class_names)\n",
    "print(\"Original class_to_idx mapping:\")\n",
    "print(base_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9668899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = TRAIN_FOLDER_PATH +\"/đông cô\" \n",
    "image_files = os.listdir(folder_path)\n",
    "image_path = os.path.join(folder_path, random.choice(image_files))\n",
    "img_original = Image.open(image_path).convert('RGB')\n",
    "img_transformed = transform(img_original)\n",
    "print(image_path)\n",
    "\n",
    "def tensor_to_img(img_tensor):\n",
    "    img = img_tensor.permute(1, 2, 0).numpy()\n",
    "    return img\n",
    "\n",
    "# Vẽ ảnh gốc và ảnh transform\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_original)\n",
    "plt.title(\"Ảnh gốc\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(tensor_to_img(img_transformed))\n",
    "plt.title(\"Sau transform\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0618eeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_class = {\n",
    "    base_dataset.class_to_idx[orig]: label_map[orig]\n",
    "    for orig in base_dataset.classes\n",
    "}\n",
    "print(\"Final class labels (used for submission):\")\n",
    "print(idx_to_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d09ee9",
   "metadata": {},
   "source": [
    "# Train/Eval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae20e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, idx_to_class, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Chuyển label và pred sang dạng label chuẩn hóa (string)\n",
    "            pred_labels = [idx_to_class[p.item()] for p in preds]\n",
    "            true_labels = [idx_to_class[l.item()] for l in labels]\n",
    "\n",
    "            all_preds.extend(pred_labels)\n",
    "            all_labels.extend(true_labels)\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    print(f'Accuracy: {acc:.4f}')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e484eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader,val_loader, epochs=30):\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')  # Initialize with a very large value\n",
    "    patience = 10  # Number of epochs to wait before early stopping\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Lists to store training and validation losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "        for inputs, labels in tqdm(dataloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Record training loss for this epoch\n",
    "        epoch_train_loss = running_loss / len(dataloader)\n",
    "        train_losses.append(epoch_train_loss) \n",
    "        print(f\"Epoch {epoch+1}, Loss: {epoch_train_loss:.4f}\", end=', ')\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                # Chuyển label và pred sang dạng label chuẩn hóa (string)\n",
    "                pred_labels = [idx_to_class[p.item()] for p in preds]\n",
    "                true_labels = [idx_to_class[l.item()] for l in labels]\n",
    "            \n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                all_preds.extend(pred_labels)\n",
    "                all_labels.extend(true_labels)\n",
    "        \n",
    "        # Record validation loss for this epoch\n",
    "        epoch_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        \n",
    "        acc = accuracy_score(all_labels, all_preds)\n",
    "        print(f'Loss Valid: {epoch_val_loss:.4f}, Accuracy Valid: {acc:.4f}')\n",
    "        # evaluate_model(model, test_loader, idx_to_class, device, df_true)\n",
    "        \n",
    "        # Early stopping check\n",
    "        if epoch_val_loss < best_val_loss: \n",
    "            best_val_loss = epoch_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered!\")\n",
    "                break  \n",
    "    scheduler.step()\n",
    "        \n",
    "    # Plotting Training and Validation Curves after training loop\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846e2a64",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a435acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(EfficientNetClassifier, self).__init__()\n",
    "        self.model = models.efficientnet_b3(pretrained=True)\n",
    "\n",
    "        # Bỏ phần classifier gốc\n",
    "        self.features = self.model.features\n",
    "\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1)) \n",
    "        in_features = self.model.classifier[1].in_features\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)                         \n",
    "        x = self.adaptive_pool(x)                    \n",
    "        x = torch.flatten(x, 1)                      \n",
    "        x = self.dropout(x)                          \n",
    "        x = self.fc(x)                               \n",
    "        return x\n",
    "\n",
    "model = EfficientNetClassifier(num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f8c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5, weight_decay=0.001) \n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.01)\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Số lượng tham số được huấn luyện: {trainable_params}\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3678e60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_loader, val_loader, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5d17ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_model(model, val_dataset, idx_to_class, device)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac84119",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef91709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(model, dataloader, idx_to_class, device):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    file_names = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, filenames in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            results.extend([idx_to_class[p.item()] for p in preds])\n",
    "            file_names.extend(filenames)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"id\": [file.split('.')[0] for file in file_names],\n",
    "        \"type\": results\n",
    "    })\n",
    "    df.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"Saved submission.csv\")\n",
    "    return df\n",
    "predcits = create_submission(model, test_loader, idx_to_class, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
